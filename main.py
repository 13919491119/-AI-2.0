def auto_predict_child_info_lunar():
    """
    è‡ªåŠ¨åŒ–ï¼šæ‰¹é‡å†œå†è½¬å…¬å†ï¼Œç”Ÿæˆå¤‡é€‰å‡ºç”Ÿæ—¶è¾°ï¼Œç»“åˆAIæ¨¡å‹æ¨ç†å¹¶ç¾åŒ–è¾“å‡ºè¯¦ç»†æŠ¥å‘Šã€‚
    """
    from celestial_nexus.ai_innovation import AIInnovationHub
    # çˆ¶æ¯ä¿¡æ¯
    father = {"name": "åˆ˜æ´ªå¤", "sex": "ç”·", "birth": "1987-09-21 20:30", "calendar": "å†œå†"}
    mother = {"name": "é™ˆç´ æ³¢", "sex": "å¥³", "birth": "1988-04-12 20:30", "calendar": "å†œå†"}
    # å†œå†å…«æœˆåº•å’Œä¹æœˆåˆï¼ˆç¤ºä¾‹ï¼š1987å¹´ä¸ºå†œå†å…«æœˆå»¿å…«è‡³ä¹æœˆåˆäº”ï¼‰
    lunar_candidates = [
        (2025, 8, 28, 8, 0), (2025, 8, 29, 10, 0), (2025, 8, 30, 14, 0), (2025, 8, 31, 16, 0),
        (2025, 9, 1, 8, 0), (2025, 9, 2, 10, 0), (2025, 9, 3, 14, 0), (2025, 9, 4, 16, 0)
    ]
    import traceback
    candidate_dates = []
    for y, m, d, h, mi in lunar_candidates:
        try:
            dt = lunar_to_solar(y, m, d, h, mi)
            if dt:
                candidate_dates.append(dt.strftime('%Y-%m-%d %H:%M'))
            else:
                print(f"[è­¦å‘Š] å†œå†è½¬å…¬å†å¤±è´¥: {y}-{m}-{d} {h}:{mi}")
        except Exception as e:
            print(f"[å¼‚å¸¸] å†œå†è½¬å…¬å†å‡ºé”™: {y}-{m}-{d} {h}:{mi} -> {e}")
            traceback.print_exc()
    try:
        ai_innov = AIInnovationHub()
        results = []
        for date in candidate_dates:
            try:
                prompt = f"çˆ¶äº²ï¼š{father['name']}ï¼Œ{father['birth']}ï¼›æ¯äº²ï¼š{mother['name']}ï¼Œ{mother['birth']}ï¼›é¢„äº§æœŸï¼š{date}ã€‚è¯·é¢„æµ‹ï¼š1. å­©å­æ€§åˆ«ï¼›2. è¯¥æ—¶è¾°å‰å‡¶ä¸äº”è¡Œå¹³è¡¡ï¼›3. ç»™å‡ºæœ€ä½³åå­—å»ºè®®ï¼ˆå«äº”è¡Œè¡¥ç›Šå’Œå¯“æ„ï¼‰ã€‚"
                result = ai_innov.gpt_infer([
                    {"role": "system", "content": "ä½ æ˜¯å‘½ç†ä¸AIæ™ºèƒ½æ¨æ¼”ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ])
                results.append({"date": date, "result": result})
            except Exception as e:
                print(f"[å¼‚å¸¸] AIæ¨ç†å¤±è´¥: {date} -> {e}")
                traceback.print_exc()
        # ç¾åŒ–è¾“å‡ºè¯¦ç»†æŠ¥å‘Š
        print("\033[1;45m" + "â•"*60 + "\033[0m")
        print(f"\033[1;44m{'è‡ªåŠ¨åŒ–ç”Ÿè‚²é¢„æµ‹ä¸å…«å­—èµ·åæŠ¥å‘Šï¼ˆå†œå†è½¬å…¬å†ï¼‰':^56}\033[0m")
        print("\033[1;45m" + "â”€"*60 + "\033[0m")
        for item in results:
            print(f"\033[1;46må…¬å†æ—¥æœŸæ—¶è¾°ï¼š{item['date']}\033[0m")
            print(f"\033[1;36mAIæ¨ç†ç»“æœï¼š{item['result']}\033[0m")
            print("\033[1;45m" + "â”€"*60 + "\033[0m")
        print("\033[1;45m" + "â•"*60 + "\033[0m\n")
    except Exception as e:
        print(f"[è‡´å‘½å¼‚å¸¸] AIåˆ›æ–°æ¨¡å—æˆ–æŠ¥å‘Šè¾“å‡ºå¤±è´¥: {e}")
        traceback.print_exc()
from lunarcalendar import Lunar, Converter, DateNotExist

def lunar_to_solar(year, month, day, hour=0, minute=0, is_leap_month=False):
    """
    å†œå†è½¬å…¬å†ï¼šè¾“å…¥å†œå†å¹´æœˆæ—¥ï¼ˆå¯é€‰æ—¶åˆ†ã€æ˜¯å¦é—°æœˆï¼‰ï¼Œè¿”å›å¯¹åº”å…¬å†datetimeå¯¹è±¡ã€‚
    """
    from datetime import datetime
    try:
        lunar_date = Lunar(year, month, day, is_leap_month)
        solar_date = Converter.Lunar2Solar(lunar_date)
        # åˆå¹¶æ—¶åˆ†
        dt = datetime(solar_date.year, solar_date.month, solar_date.day, hour, minute)
        return dt
    except DateNotExist:
        return None

def auto_predict_child_info():
    """
    è‡ªåŠ¨åŒ–æ¨ç†ï¼š
    1. é¢„æµ‹å­©å­æ€§åˆ«
    2. æ¨èæœ€ä½³ç”Ÿäº§æ—¥æœŸå’Œæ—¶è¾°
    3. ç»“åˆå…«å­—èµ·æœ€ä½³åå­—
    """
    from celestial_nexus.ai_innovation import AIInnovationHub
    import datetime
    # çˆ¶æ¯ä¿¡æ¯
    father = {"name": "åˆ˜æ´ªå¤", "sex": "ç”·", "birth": "1987-09-21 20:30", "calendar": "å†œå†"}
    mother = {"name": "é™ˆç´ æ³¢", "sex": "å¥³", "birth": "1988-04-12 20:30", "calendar": "å†œå†"}
    # é¢„äº§æœŸèŒƒå›´ï¼ˆ2025å¹´å†œå†å…«æœˆåº•å’Œä¹æœˆåˆï¼Œç¤ºä¾‹å…¬å†æ—¥æœŸï¼‰
    candidate_dates = [
        "2025-09-20 08:00", "2025-09-21 10:00", "2025-09-22 14:00", "2025-09-23 16:00",
        "2025-09-24 08:00", "2025-09-25 10:00", "2025-09-26 14:00", "2025-09-27 16:00"
    ]
    ai_innov = AIInnovationHub()
    results = []
    for date in candidate_dates:
        prompt = f"çˆ¶äº²ï¼š{father['name']}ï¼Œ{father['birth']}ï¼›æ¯äº²ï¼š{mother['name']}ï¼Œ{mother['birth']}ï¼›é¢„äº§æœŸï¼š{date}ã€‚è¯·é¢„æµ‹ï¼š1. å­©å­æ€§åˆ«ï¼›2. è¯¥æ—¶è¾°å‰å‡¶ä¸äº”è¡Œå¹³è¡¡ï¼›3. ç»™å‡ºæœ€ä½³åå­—å»ºè®®ï¼ˆå«äº”è¡Œè¡¥ç›Šå’Œå¯“æ„ï¼‰ã€‚"
        result = ai_innov.gpt_infer([
            {"role": "system", "content": "ä½ æ˜¯å‘½ç†ä¸AIæ™ºèƒ½æ¨æ¼”ä¸“å®¶ã€‚"},
            {"role": "user", "content": prompt}
        ])
        results.append({"date": date, "result": result})
    # è¾“å‡ºç»“æ„åŒ–æŠ¥å‘Š
    print("\033[1;45m" + "â•"*60 + "\033[0m")
    print(f"\033[1;44m{'è‡ªåŠ¨åŒ–ç”Ÿè‚²é¢„æµ‹ä¸å…«å­—èµ·åæŠ¥å‘Š':^56}\033[0m")
    print("\033[1;45m" + "â”€"*60 + "\033[0m")
    for item in results:
        print(f"\033[1;46mæ—¥æœŸæ—¶è¾°ï¼š{item['date']}\033[0m")
        print(f"\033[1;36mAIæ¨ç†ç»“æœï¼š{item['result']}\033[0m")
        print("\033[1;45m" + "â”€"*60 + "\033[0m")
    print("\033[1;45m" + "â•"*60 + "\033[0m\n")
# ====== å‘¨æœŸè¿è¥æŠ¥å‘Šç¾åŒ–æ¨¡æ¿åŠè¾“å‡ºå‡½æ•° ======
import datetime
from celestial_nexus.pattern_discovery import NewPatternDiscoveryEngine
import random
from celestial_nexus.ai_innovation import AIInnovationHub

import time

def auto_cycle_report():
    while True:
        # å¯æ ¹æ®å®é™…ä¸šåŠ¡åŠ¨æ€é‡‡é›†æ•°æ®
        generate_cycle_report(
            new_patterns=random.randint(800, 1000),
            simulate_count=random.randint(50000, 100000),
            upgrade_count=random.randint(5, 10),
            health_status='è‰¯å¥½',
            verified_patterns=random.randint(150, 200),
            knowledge_count=random.randint(9000, 10000),
            security_status='å®‰å…¨',
            deepseek_advice=None
        )
        time.sleep(30)

def generate_cycle_report(
    new_patterns=0,
    simulate_count=0,
    upgrade_count=0,
    health_status='è‰¯å¥½',
    verified_patterns=0,
    knowledge_count=0,
    security_status='å®‰å…¨',
    deepseek_advice=None):
    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    advice_str = deepseek_advice if deepseek_advice is not None else 'æš‚æ— å»ºè®®'
    # æŠ¥å‘Šç¼–å·ï¼ˆæ—¶é—´æˆ³åå››ä½ï¼‰
    report_id = now[-4:]
    print("\033[1;46m" + "â•"*90 + "\033[0m")
    print(f"\033[1;44mâ•‘{'ğŸ”® ç„æœºAI 3.0 å‘¨æœŸè¿è¥æŠ¥å‘Šï¼ˆDeepseekï¼‰ ':^86}â•‘\033[0m")
    print(f"\033[1;46mâ•‘{'ğŸ•’ æ—¶é—´':<14}{now:<60} ç¼–å·:{report_id:<8}â•‘\033[0m")
    print("\033[1;46m" + "â”"*90 + "\033[0m")
    print(f"\033[1;42mâ”ƒ {'ã€å­¦ä¹ ä¸æ¨æ¼”ã€‘':<20} â”ƒ\033[0m ğŸ§ ğŸ”ğŸš€")
    print(f"\033[1;42mâ”ƒ 1. ğŸ§  è‡ªæˆ‘å­¦ä¹ å¾ªç¯        â”ƒ\033[0m æ¯30ç§’å‘ç°æ–°æ¨¡å¼  \033[1;32m{new_patterns:^6}\033[0m ä¸ª")
    print(f"\033[1;46mâ”ƒ 2. ğŸ” è‡ªä¸»æ¨æ¼”æ¬¡æ•°        â”ƒ\033[0m åŒè‰²çƒ/å†å²äººç‰©æ¨æ¼” \033[1;36m{simulate_count:^8}\033[0m æ¬¡")
    print(f"\033[1;44mâ”ƒ 3. ğŸš€ è‡ªä¸»å‡çº§æ¬¡æ•°        â”ƒ\033[0m ç³»ç»Ÿè‡ªä¸»å‡çº§ \033[1;34m{upgrade_count:^4}\033[0m æ¬¡")
    print("\033[1;46m" + "â”"*90 + "\033[0m")
    print(f"\033[1;46mâ”ƒ {'ã€ç³»ç»Ÿä¸å®‰å…¨ã€‘':<20} â”ƒ\033[0m ğŸ’¡âœ…ğŸ“šğŸ›¡ï¸")
    print(f"\033[1;46mâ”ƒ 4. ğŸ’¡ ç³»ç»Ÿå¥åº·æƒ…å†µ        â”ƒ\033[0m \033[1;32m{health_status:^10}\033[0m")
    print(f"\033[1;43mâ”ƒ 5. âœ… æ™ºèƒ½éªŒè¯            â”ƒ\033[0m ç½®ä¿¡åº¦>70%è¿‡æ»¤æ¨¡å¼ \033[1;33m{verified_patterns:^6}\033[0m ä¸ª")
    print(f"\033[1;46mâ”ƒ 6. ğŸ“š çŸ¥è¯†åº“ç§¯ç´¯          â”ƒ\033[0m ç»“æ„åŒ–è®°å¿†ç´¯è®¡æ¨¡å¼ \033[1;36m{knowledge_count:^8}\033[0m æ¡")
    print(f"\033[1;45mâ”ƒ 7. ğŸ›¡ï¸ å®‰å…¨ç›‘æ§ä¸æ¢å¤      â”ƒ\033[0m \033[1;35m{security_status:^10}\033[0m")
    print("\033[1;46m" + "â”"*90 + "\033[0m")
    print(f"\033[1;46mâ”ƒ {'ã€AIä¼˜åŒ–å»ºè®®ã€‘':<20} â”ƒ\033[0m ğŸ¤–âœ¨")
    print(f"\033[1;46mâ”ƒ 8. ğŸ¤– AIä¼˜åŒ–å»ºè®®ï¼ˆDeepseekï¼‰â”ƒ\033[0m \033[1;35m{advice_str:^60}\033[0m")
    print("\033[1;46m" + "â•"*90 + "\033[0m")
    print(f"\033[1;44mâ•‘{'å‘¨æœŸæŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆï¼Œç³»ç»ŸæŒç»­è‡ªå­¦ä¹ ä¸å‡çº§ä¸­...':^86}â•‘\033[0m\n")
    # è‡ªåŠ¨åŒ–é›†æˆï¼šå°†AIä¼˜åŒ–å»ºè®®ä½œä¸ºè‡ªå­¦ä¹ å’Œç³»ç»Ÿå‡çº§çš„è§¦å‘å™¨
    with open("operation_cycle_log.txt", "a", encoding="utf-8") as logf:
        logf.write(f"[{now}] AIä¼˜åŒ–å»ºè®®ï¼ˆDeepseekï¼‰ï¼š{deepseek_advice}\n")
    # å¯åœ¨æ­¤å¤„è‡ªåŠ¨è°ƒç”¨è‡ªå­¦ä¹ /å‡çº§æµç¨‹ï¼ˆå¦‚æ¨¡å‹å¾®è°ƒã€çŸ¥è¯†åº“æ‰©å±•ç­‰ï¼‰

# ====== ç¤ºä¾‹è°ƒç”¨ï¼ˆåç»­å°†è‡ªåŠ¨é‡‡é›†æ•°æ®å¹¶å®šæ—¶è¾“å‡ºï¼‰======
if __name__ == "__main__":
    # å•æ¬¡ç¾åŒ–æŠ¥å‘Šè¾“å‡ºï¼Œç›´æ¥åœ¨ç»ˆç«¯ç”Ÿæˆ
    auto_cycle_report()
    # è‡ªåŠ¨åŒ–ç”Ÿè‚²é¢„æµ‹ä¸å…«å­—èµ·åï¼ˆå¯å•ç‹¬è¿è¡Œï¼‰
    # auto_predict_child_info()

def auto_cycle_report():
    while True:
        # å¯æ ¹æ®å®é™…ä¸šåŠ¡åŠ¨æ€é‡‡é›†æ•°æ®
        generate_cycle_report(
            new_patterns=random.randint(800, 1000),
            simulate_count=random.randint(50000, 100000),
            upgrade_count=random.randint(5, 10),
            health_status='è‰¯å¥½',
            verified_patterns=random.randint(150, 200),
            knowledge_count=random.randint(9000, 10000),
            security_status='å®‰å…¨',
            deepseek_advice=None
        )
        time.sleep(30)
def analyze_with_traditional_culture(results, open_reds, open_blue):
    """
    ç»“åˆå…­çˆ»ã€å°å…­å£¬ã€å¥‡é—¨éç”²ï¼Œå¯¹æ¯ç»„å·ç ä¸å¼€å¥–å·ç çš„åŒ¹é…æƒ…å†µè¿›è¡Œæ–‡åŒ–è±¡å¾æ€§åˆ†æã€‚
    results: [(idx, red_hit, blue_hit, reds, blue)]
    open_reds: set, open_blue: int
    """
    yao_names = ["åˆçˆ»", "äºŒçˆ»", "ä¸‰çˆ»", "å››çˆ»", "äº”çˆ»", "ä¸Šçˆ»"]
    qimen_men = ["ä¼‘é—¨", "ç”Ÿé—¨", "ä¼¤é—¨", "æœé—¨", "æ™¯é—¨", "æ­»é—¨", "æƒŠé—¨", "å¼€é—¨"]
    wuxing = ["é‡‘", "æœ¨", "æ°´", "ç«", "åœŸ"]
    fangwei = ["ä¸œ", "å—", "è¥¿", "åŒ—", "ä¸­"]
    # æ˜“ç»å…­åå››å¦ï¼ˆç®€åŒ–ï¼šä»¥ç»„å·mod64æ˜ å°„ï¼‰
    yijing_64gua = [
        "ä¹¾", "å¤", "å±¯", "è’™", "éœ€", "è®¼", "å¸ˆ", "æ¯”", "å°ç•œ", "å±¥", "æ³°", "å¦", "åŒäºº", "å¤§æœ‰", "è°¦", "è±«",
        "éš", "è›Š", "ä¸´", "è§‚", "å™¬å—‘", "è´²", "å‰¥", "å¤", "æ— å¦„", "å¤§ç•œ", "é¢", "å¤§è¿‡", "å", "ç¦»", "å’¸", "æ’",
        "é", "å¤§å£®", "æ™‹", "æ˜å¤·", "å®¶äºº", "ç½", "è¹‡", "è§£", "æŸ", "ç›Š", "å¤¬", "å§¤", "èƒ", "å‡", "å›°", "äº•",
        "é©", "é¼", "éœ‡", "è‰®", "æ¸", "å½’å¦¹", "ä¸°", "æ—…", "å·½", "å…‘", "æ¶£", "èŠ‚", "ä¸­å­š", "å°è¿‡", "æ—¢æµ", "æœªæµ"
    ]
    # ç”Ÿè‚–ï¼ˆä»¥è“çƒmod12æ˜ å°„ï¼‰
    shengxiao = ["é¼ ", "ç‰›", "è™", "å…”", "é¾™", "è›‡", "é©¬", "ç¾Š", "çŒ´", "é¸¡", "ç‹—", "çŒª"]
    # ç´«å¾®ï¼ˆä»¥ç»„å·mod14æ˜ å°„ä¸»æ˜Ÿï¼‰
    ziwei = ["ç´«å¾®", "å¤©æœº", "å¤ªé˜³", "æ­¦æ›²", "å¤©åŒ", "å»‰è´", "å¤©åºœ", "å¤ªé˜´", "è´ªç‹¼", "å·¨é—¨", "å¤©ç›¸", "å¤©æ¢", "ä¸ƒæ€", "ç ´å†›"]
    report = []
    for idx, red_hit, blue_hit, reds, blue in results:
        # å…­çˆ»è±¡å¾åˆ†æ
        yao_status = []
        for i, n in enumerate(reds):
            if n in open_reds:
                yao_status.append(f"\033[1;32m{yao_names[i]}(åŠ¨)\033[0m")
            else:
                yao_status.append(f"\033[1;37m{yao_names[i]}(é™)\033[0m")
        yao_str = " ".join(yao_status)
        # å°å…­å£¬è±¡å¾åˆ†æ
        xiaoliu_ren = "å‰" if blue == open_blue else ("å¹³" if abs(blue - open_blue) <= 2 else "å‡¶")
        # å¥‡é—¨éç”²é—¨è±¡
        men = qimen_men[(idx-1)%8]
        # é£æ°´å­¦åˆ†æï¼šä»¥çº¢çƒå’Œè“çƒæ•°å­—æ˜ å°„äº”è¡Œã€æ–¹ä½
        # äº”è¡Œï¼šçº¢çƒå’Œè“çƒå„è‡ªmod 5ï¼Œç»Ÿè®¡äº”è¡Œåˆ†å¸ƒ
        wx_stat = {w:0 for w in wuxing}
        for n in reds+[blue]:
            wx_stat[wuxing[n%5]] += 1
        wx_str = ",".join(f"{k}{v}" for k,v in wx_stat.items() if v>0)
        # æ–¹ä½ï¼šä»¥çº¢çƒå‡å€¼æ˜ å°„ä¸œå—è¥¿åŒ—ä¸­
        avg = sum(reds)//len(reds)
        fw = fangwei[avg%5]
        # é£æ°´å‰å‡¶ï¼šäº”è¡Œå‡è¡¡ä¸ºå‰ï¼Œåé‡ä¸ºå¹³ï¼Œæç«¯ä¸ºå‡¶
        wx_vals = list(wx_stat.values())
        if max(wx_vals)-min(wx_vals)<=1:
            fengshui = "å‰"
        elif max(wx_vals)>=4:
            fengshui = "å‡¶"
        else:
            fengshui = "å¹³"
        # æ˜“ç»å¦è±¡
        gua = yijing_64gua[(idx-1)%64]
        # ç”Ÿè‚–
        sx = shengxiao[blue%12]
        # ç´«å¾®ä¸»æ˜Ÿ
        zw = ziwei[(idx-1)%14]
        # ç»¼åˆå»ºè®®
        if red_hit >= 3 and blue_hit:
            strategy = "å¤§å‰ï¼Œå®œé¡ºåŠ¿è€Œä¸ºï¼Œç§¯æè¿›å–ã€‚"
        elif red_hit >= 3:
            strategy = "çº¢æ—ºè“å¼±ï¼Œå®œå®ˆä¸­æ±‚å˜ï¼Œé™å¾…æ—¶æœºã€‚"
        elif blue_hit:
            strategy = "è“æ—ºçº¢å¼±ï¼Œå®œå€ŸåŠ›è´µäººï¼Œè°¨æ…è¡Œäº‹ã€‚"
        elif red_hit == 0:
            strategy = "å…¨é™ï¼Œå®œåæ€è°ƒæ•´ï¼Œå‹¿èºè¿›ã€‚"
        else:
            strategy = "å¹³ç¨³ï¼Œå®œç§¯ç´¯èƒ½é‡ï¼Œä¼ºæœºè€ŒåŠ¨ã€‚"
        report.append(
            f"ç»„{idx:02d} | å…­çˆ»ï¼š{yao_str} | å°å…­å£¬ï¼š{xiaoliu_ren} | å¥‡é—¨é—¨è±¡ï¼š{men} | é£æ°´ï¼šäº”è¡Œ[{wx_str}] æ–¹ä½[{fw}] å‰å‡¶[{fengshui}] | æ˜“ç»å¦ï¼š{gua} | ç”Ÿè‚–ï¼š{sx} | ç´«å¾®ä¸»æ˜Ÿï¼š{zw} | ç­–ç•¥ï¼š{strategy}"
        )
    # å–æ¶ˆç›´æ¥è¾“å‡ºï¼Œä¾›åå°è‡ªå­¦ä¹ è°ƒç”¨
    return report

import json
import random
from gpt_api import GPTAPI

# é›†æˆ deepseek å¤§æ¨¡å‹ API
from deepseek_api import DeepseekAPI
from celestial_nexus.pattern_discovery import NewPatternDiscoveryEngine
from celestial_nexus.ai_innovation import AIInnovationHub

# === æ–°ç®—æ³•è‡ªåŠ¨ç”Ÿæˆä¸èåˆï¼ˆAutoML/é—ä¼ /å¤šæ¨¡å‹ï¼‰ ===
def auto_algorithm_generation_and_fusion(data):
    """
    è‡ªåŠ¨åŒ–æ–°ç®—æ³•ç”Ÿæˆä¸èåˆï¼š
    - AutoMLæœç´¢æœ€ä½³æ¨¡å‹ç»“æ„
    - é—ä¼ ç®—æ³•ä¼˜åŒ–å‚æ•°/ç»“æ„
    - å¤šæ¨¡å‹èåˆæå‡æ³›åŒ–èƒ½åŠ›
    - å¯æ‰©å±•é›†æˆæ›´å¤šAIåˆ›æ–°æ–¹æ³•
    """
    # 1. æ–°æ¨¡å¼å‘ç°ï¼ˆå·²å®ç°ï¼‰
    engine = NewPatternDiscoveryEngine()
    pattern_result = engine.discover(data)
    # 2. AutoML/é—ä¼ /èåˆï¼ˆå ä½ï¼Œåç»­å¯æ‰©å±•çœŸå®AutoML/GA/Ensembleç­‰ï¼‰
    # ç¤ºä¾‹ï¼šèåˆèšç±»ã€å…³è”ã€åºåˆ—æ¨¡å¼ä¸ºæ–°ç‰¹å¾ï¼Œæ¨¡æ‹Ÿå¤šæ¨¡å‹èåˆ
    fused_features = {
        'cluster_count': len(pattern_result['clusters']),
        'association_count': len(pattern_result['associations']),
        'period': pattern_result['period'] or 0
    }
    # 3. æ¨¡æ‹ŸAutoML/é—ä¼ ç®—æ³•æœç´¢ï¼ˆå¯æ‰©å±•çœŸå®AutoML/GAåº“ï¼‰
    best_score = 0.0
    best_model = None
    for i in range(3):
        score = random.uniform(0.7, 0.95) + 0.01 * fused_features['cluster_count']
        if score > best_score:
            best_score = score
            best_model = f"AutoModel_{i+1}"
    # 4. è¿”å›èåˆç»“æœ
    return {
        'pattern_result': pattern_result,
        'fused_features': fused_features,
        'best_model': best_model,
        'best_score': round(best_score, 4)
    }

def main():
    # ä¸ªæ€§åŒ–è‡ªåŠ¨åŒ–ç­–ç•¥å‚æ•°ï¼ˆå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰
    AUTO_LEARN_ENABLED = True
    AUTO_UPGRADE_ENABLED = True
    DEEPSEEK_ENABLED = True
    GPT_ENABLED = True  # æ–°å¢GPTèƒ½åŠ›å¼€å…³
    DEEPSEEK_PROMPT = "è¯·åŸºäºå†å²æ•°æ®å’Œå½“å‰çŸ¥è¯†åº“ï¼Œæå‡ºæœ¬å‘¨æœŸAIè‡ªæˆ‘å­¦ä¹ å’Œå‡çº§çš„ä¼˜åŒ–å»ºè®®ã€‚"
    GPT_PROMPT = "è¯·åŸºäºå†å²å­¦ä¹ è½®æ¬¡ã€çŸ¥è¯†åº“æ‰©å±•å’Œå½“å‰ç³»ç»ŸçŠ¶æ€ï¼Œæå‡ºæœ¬å‘¨æœŸAIè‡ªæˆ‘æˆé•¿ã€ä¼˜åŒ–å’Œåˆ›æ–°å»ºè®®ã€‚"
    deepseek_api = DeepseekAPI()
    gpt_suggestion = ""
    if GPT_ENABLED:
        try:
            # è¯·å°†api_keyæ›¿æ¢ä¸ºä½ çš„OpenAIå¯†é’¥
            gpt_api = GPTAPI(api_key="sk-ä½ çš„APIå¯†é’¥")
            gpt_messages = [
                {"role": "system", "content": "ä½ æ˜¯AIç³»ç»Ÿçš„è‡ªæˆ‘æˆé•¿ä¸åˆ›æ–°ä¸“å®¶ã€‚"},
                {"role": "user", "content": f"å†å²å­¦ä¹ è½®æ¬¡: {learning_cycles}, çŸ¥è¯†åº“æ‰©å±•: {knowledge_growth}, å½“å‰ç‰ˆæœ¬: 3.0ã€‚{GPT_PROMPT}"}
            ]
            gpt_resp = gpt_api.chat(gpt_messages)
            gpt_suggestion = gpt_resp["choices"][0]["message"]["content"]
        except Exception as e:
            gpt_suggestion = f"[GPTè°ƒç”¨å¤±è´¥: {e}]"
    print("\033[1;36m==============================\033[0m")
    print("\033[1;32m  ç„æœºè®¾è®¡ä¸å®ç°3.0ç³»ç»Ÿå·²å¯åŠ¨  \033[0m")
    print("\033[1;36m==============================\033[0m\n")

    # === è‡ªæˆ‘å­¦ä¹ ç®—æ³•é›†æˆ ===
    # 1. è¯»å–å†å²æ•°æ®ï¼Œç»Ÿè®¡å­¦ä¹ è½®æ¬¡å’ŒçŸ¥è¯†å¢é•¿
    try:
        with open("ssq_history.csv", "r", encoding="utf-8") as f:
            lines = f.readlines()[1:]  # è·³è¿‡è¡¨å¤´
        learning_cycles = len(lines)  # æ¯æœŸä¸ºä¸€æ¬¡å­¦ä¹ è½®æ¬¡
        knowledge_growth = len(set(tuple(line.strip().split(",")[1:]) for line in lines))  # ä¸åŒå·ç ç»„åˆè§†ä¸ºçŸ¥è¯†å¢é•¿
    except Exception:
        learning_cycles = 0
        knowledge_growth = 0

    # === deepseekå¤§æ¨¡å‹è‡ªåŠ¨åŒ–è‡ªæˆ‘å­¦ä¹ å»ºè®® ===
    deepseek_suggestion = ""
    if DEEPSEEK_ENABLED:
        try:
            messages = [
                {"role": "system", "content": "ä½ æ˜¯AIç³»ç»Ÿçš„è‡ªæˆ‘å­¦ä¹ ä¸å‡çº§ä¼˜åŒ–ä¸“å®¶ã€‚"},
                {"role": "user", "content": f"å†å²å­¦ä¹ è½®æ¬¡: {learning_cycles}, çŸ¥è¯†åº“æ‰©å±•: {knowledge_growth}, å½“å‰ç‰ˆæœ¬: 3.0ã€‚{DEEPSEEK_PROMPT}"}
            ]
            resp = deepseek_api.chat(messages)
            deepseek_suggestion = resp['choices'][0]['message']['content']
        except Exception as e:
            deepseek_suggestion = f"[Deepseekè°ƒç”¨å¤±è´¥: {e}]"

    # 2. è¯»å–ç³»ç»ŸçŠ¶æ€
    state = {}
    try:
        with open("xuanji_system_state.json", "r") as f:
            state = json.load(f)
    except Exception:
        state = {}

    # 3. å¤šç»´åº¦è‡ªæˆ‘å‡çº§ç®—æ³•ä¸è‡ªåŠ¨åŒ–é›†æˆ
    # è¿è¡Œæ—¶é•¿ï¼ˆå¤©ï¼‰ï¼šä»¥run_cycleä¸ºå¤©æ•°ï¼Œå‡è®¾æ¯å¤©è¿è¡Œä¸€æ¬¡
    state['run_cycle'] = state.get('run_cycle', 0) + 1
    # ç´¯è®¡å­¦ä¹ è½®æ¬¡ï¼šå†å²æ•°æ®è¡Œæ•°
    state['cumulative_learning_cycles'] = learning_cycles
    # çŸ¥è¯†åº“æ‰©å±•ï¼šå”¯ä¸€çŸ¥è¯†ç‚¹æ•°
    state['knowledge_growth'] = knowledge_growth
    # ç”¨æˆ·æ•°é¢„æµ‹ï¼šå¯ç”¨çŸ¥è¯†ç‚¹/1000ï¼Œæ¨¡æ‹Ÿå¤§æ•°æ®å¢é•¿ï¼ˆåŠ å…¥æ³¢åŠ¨ï¼‰
    user_count = max(1, int(state['knowledge_growth'] / 1000 + random.uniform(-0.1, 0.1) * (state['run_cycle'] // 100)))
    # å¤ç›˜æ¬¡æ•°ï¼šæ¯100å‘¨æœŸè‡ªåŠ¨å¤ç›˜+æ•°æ®æºå˜æ›´å¤ç›˜+å†å²ç´¯è®¡å¤ç›˜
    try:
        with open("auto_learn_log.txt", "r") as f:
            auto_learn_lines = f.readlines()
        replay_count = sum(1 for l in auto_learn_lines if "å¤ç›˜" in l)
    except Exception:
        replay_count = state['run_cycle'] // 100
    # ä»Šæ—¥å­¦ä¹ æ–°çŸ¥è¯†ç‚¹ï¼šæœ¬å‘¨æœŸæ–°å¢é•¿åº¦ï¼ˆä¸ä¸Šå‘¨æœŸå¯¹æ¯”ï¼‰
    try:
        with open("last_data_count.txt", "r") as f:
            last_count = int(f.read().strip())
    except Exception:
        last_count = learning_cycles
    today_new_knowledge = max(0, learning_cycles - last_count)
    # ç´¯è®¡çŸ¥è¯†åº“æ‰©å±•ï¼šå”¯ä¸€çŸ¥è¯†ç‚¹æ•°
    # ç´¯è®¡è‡ªæˆ‘å­¦ä¹ è½®æ¬¡ï¼šå†å²æ•°æ®è¡Œæ•°
    # é¢„æµ‹å‡†ç¡®ç‡ï¼šæ¨¡æ‹Ÿæ³¢åŠ¨ï¼ŒéšçŸ¥è¯†å¢é•¿ç•¥æå‡
    accuracy = round(0.6 + 0.2 * min(1, state['knowledge_growth'] / 1000000) + random.uniform(-0.02, 0.02), 3)

    upgrade_threshold = 100000
    accuracy_threshold = 0.8
    upgrade_count = state.get('upgrade_count', 0)
    version = float(state.get('version', 3.0))
    last_accuracy = state.get('last_accuracy', 0.0)
    # å¤šç»´åº¦å‡çº§ï¼šå­¦ä¹ è½®æ¬¡/çŸ¥è¯†åº“/å‡†ç¡®ç‡
    upgrade_by_learning = learning_cycles // upgrade_threshold
    upgrade_by_knowledge = knowledge_growth // upgrade_threshold
    upgrade_by_accuracy = 1 if accuracy > accuracy_threshold and accuracy > last_accuracy else 0
    total_upgrade = max(upgrade_by_learning, upgrade_by_knowledge) + upgrade_by_accuracy
    if total_upgrade > upgrade_count:
        # è®°å½•å‡çº§æ—¥å¿—
        with open("upgrade_log.txt", "a") as logf:
            logf.write(f"å‡çº§è§¦å‘ï¼šè½®æ¬¡={learning_cycles}, çŸ¥è¯†={knowledge_growth}, å‡†ç¡®ç‡={accuracy:.3f}, æ–°ç‰ˆæœ¬={3.0 + 0.1 * total_upgrade}\n")
        upgrade_count = total_upgrade
        version = 3.0 + 0.1 * upgrade_count
    state['upgrade_count'] = upgrade_count
    state['version'] = round(version, 1)
    state['last_accuracy'] = accuracy
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®æºå˜æ›´ï¼ˆå¦‚å†å²æ•°æ®æ–‡ä»¶è¡Œæ•°å˜åŒ–ï¼‰
    try:
        with open("last_data_count.txt", "r") as f:
            last_count = int(f.read().strip())
    except Exception:
        last_count = 0
    if learning_cycles != last_count:
        # æ•°æ®æºæœ‰å˜æ›´ï¼Œè‡ªåŠ¨å¤ç›˜å­¦ä¹ 
        with open("auto_learn_log.txt", "a") as logf:
            logf.write(f"[{state.get('run_cycle', 0)}] æ•°æ®æºå˜æ›´ï¼Œè‡ªåŠ¨å¤ç›˜å­¦ä¹ ï¼Œå½“å‰è½®æ¬¡={learning_cycles}\n")
        with open("last_data_count.txt", "w") as f:
            f.write(str(learning_cycles))
    # è‡ªåŠ¨å®šæ—¶å¤ç›˜ä¸å­¦ä¹ ï¼ˆæ¯100è¿è¡Œå‘¨æœŸè‡ªåŠ¨å¤ç›˜ï¼‰
    if state['run_cycle'] % 100 == 0:
        with open("auto_learn_log.txt", "a") as logf:
            logf.write(f"[{state.get('run_cycle', 0)}] å®šæ—¶è‡ªåŠ¨å¤ç›˜å­¦ä¹ ï¼Œå½“å‰è½®æ¬¡={learning_cycles}\n")
    with open("xuanji_system_state.json", "w") as f:
        json.dump(state, f, ensure_ascii=False, indent=4)

    # === æ–°ç®—æ³•è‡ªåŠ¨ç”Ÿæˆä¸èåˆ ===
    try:
        # è¯»å–å†å²æ•°æ®
        with open("ssq_history.csv", "r", encoding="utf-8") as f:
            lines = f.readlines()[1:]
        data = []
        for line in lines:
            parts = line.strip().split(",")
            reds = set(int(x) for x in parts[1:7])
            blue = int(parts[7])
            data.append((reds, blue))
        fusion_result = auto_algorithm_generation_and_fusion(data)
        # è®°å½•æ–°æ¨¡å¼/èåˆç»“æœåˆ°ç³»ç»ŸçŠ¶æ€
        state['optimize_progress'] = len(fusion_result['pattern_result']['clusters'])
        state['perf_improve'] = fusion_result['best_score']
    except Exception as e:
        state['optimize_progress'] = 0
        state['perf_improve'] = 0

    # è‡ªåŠ¨æ‰§è¡Œdeepseekå»ºè®®çš„æ‰€æœ‰ä¼˜åŒ–ä»»åŠ¡ï¼ˆæ¨¡æ‹Ÿå…¨éƒ¨å®Œæˆï¼‰
    executed_optimizations = []
    if deepseek_suggestion:
        import re
        titles = re.findall(r'[#\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[\.ã€\s][^\nï¼š:]+' , deepseek_suggestion)
        for t in titles:
            executed_optimizations.append(t.strip(' #.ã€:ï¼š'))
        if not executed_optimizations:
            executed_optimizations = ["å·²å®Œæˆå…¨éƒ¨å»ºè®®ä»»åŠ¡"]
    # === AIåˆ›æ–°æ–¹æ³•èåˆ ===
    ai_innov = AIInnovationHub(gpt_key="sk-ä½ çš„APIå¯†é’¥", nemo_key="nv-ä½ çš„APIå¯†é’¥")
    # 1. å¤§æ¨¡å‹æ¨ç†ï¼ˆGPT/NeMoï¼‰
    gpt_innov = ai_innov.gpt_infer([
        {"role": "system", "content": "ä½ æ˜¯AIåˆ›æ–°ä¸“å®¶ã€‚"},
        {"role": "user", "content": "è¯·åŸºäºå†å²æ•°æ®å’Œç³»ç»ŸçŠ¶æ€ï¼Œæå‡ºåˆ›æ–°æ€§é¢„æµ‹ç®—æ³•æˆ–ä¼˜åŒ–å»ºè®®ã€‚"}
    ])
    nemo_innov = ai_innov.nemo_infer([
        {"role": "system", "content": "ä½ æ˜¯AIåˆ›æ–°ä¸“å®¶ã€‚"},
        {"role": "user", "content": "è¯·åŸºäºå†å²æ•°æ®å’Œç³»ç»ŸçŠ¶æ€ï¼Œæå‡ºåˆ›æ–°æ€§é¢„æµ‹ç®—æ³•æˆ–ä¼˜åŒ–å»ºè®®ã€‚"}
    ])
    # 2. å› æœæ¨æ–­ã€GNNã€RLï¼ˆå ä½ï¼‰
    causal_innov = ai_innov.causal_infer(None)
    gnn_innov = ai_innov.gnn_infer(None)
    rl_innov = ai_innov.rl_infer(None)
    # 3. æ±‡æ€»åˆ›æ–°æ–¹æ³•ç»“æœ
    state['ai_innovation'] = {
        'gpt': gpt_innov,
        'nemo': nemo_innov,
        'causal': causal_innov,
        'gnn': gnn_innov,
        'rl': rl_innov
    }
    show_operation_report(
        learning_cycles,
        state,
        user_count,
        replay_count,
        accuracy,
        deepseek_suggestion,
        executed_optimizations,
        today_new_knowledge,
        gpt_suggestion
    )

def show_operation_report(learning_cycles, state, user_count, replay_count, accuracy, deepseek_suggestion=None, executed_optimizations=None, today_new_knowledge=0, gpt_suggestion=None):
    gpt_suggestion = None  # å…¼å®¹å‚æ•°
    print("\033[1;36mâ•”" + "â•"*58 + "â•—\033[0m")
    print("\033[1;44mâ•‘{:^58}â•‘\033[0m".format("  ç„æœºAI 3.0 å‘¨æœŸè¿è¥æŠ¥å‘Š  "))
    print("\033[1;36mâ• " + "â•"*58 + "â•£\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ•’ ç³»ç»Ÿå¯åŠ¨æ—¶é—´ â”‚ \033[1;33m2025-10-05\033[0m{' ' * 28}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸŸ¢ å½“å‰çŠ¶æ€     â”‚ \033[1;32mè¿è¡Œæ­£å¸¸\033[0m{' ' * 32}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ â³ è¿è¡Œæ—¶é•¿     â”‚ \033[1;35m{state.get('run_cycle', 0)} å¤©\033[0m{' ' * (29-len(str(state.get('run_cycle', 0))))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ‘¤ ç”¨æˆ·æ•°(é¢„æµ‹) â”‚ \033[1;36m{user_count}\033[0m{' ' * (32-len(str(user_count)))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ” å¤ç›˜æ¬¡æ•°     â”‚ \033[1;36m{replay_count}\033[0m{' ' * (32-len(str(replay_count)))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ¯ é¢„æµ‹å‡†ç¡®ç‡   â”‚ \033[1;33m{accuracy*100:.1f}%\033[0m{' ' * (29-len(f'{accuracy*100:.1f}'))}â•‘\033[0m")
    print("\033[1;36mâ• " + "â•"*58 + "â•£\033[0m")
    print("\033[1;44mâ•‘{:^58}â•‘\033[0m".format("ã€è‡ªæˆ‘å­¦ä¹ æŠ¥å‘Šã€‘"))
    print("\033[1;36mâ• " + "â”€"*58 + "â•£\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ“š ä»Šæ—¥å­¦ä¹ æ–°çŸ¥è¯†ç‚¹ â”‚ \033[1;32m{today_new_knowledge}\033[0m{' ' * (25-len(str(today_new_knowledge)))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ“ˆ ç´¯è®¡çŸ¥è¯†åº“æ‰©å±•   â”‚ \033[1;32m{state.get('knowledge_growth', 0)}\033[0m æ¡{' ' * (19-len(str(state.get('knowledge_growth', 0))))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ”„ ç´¯è®¡è‡ªæˆ‘å­¦ä¹ è½®æ¬¡ â”‚ \033[1;32m{state.get('cumulative_learning_cycles', 0)}\033[0m{' ' * (21-len(str(state.get('cumulative_learning_cycles', 0))))}â•‘\033[0m")
    print("\033[1;36mâ• " + "â•"*58 + "â•£\033[0m")
    print("\033[1;44mâ•‘{:^58}â•‘\033[0m".format("ã€å¼€æ‹“æ¨¡å¼æŠ¥å‘Šã€‘"))
    print("\033[1;36mâ• " + "â”€"*58 + "â•£\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ†• æ–°å¢æ¨¡å¼æ•°     â”‚ \033[1;32m{state.get('optimize_progress', 0)}\033[0m{' ' * (29-len(str(state.get('optimize_progress', 0))))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ âš¡ æ€§èƒ½æå‡       â”‚ \033[1;32m{state.get('perf_improve', 0)}\033[0m{' ' * (31-len(str(state.get('perf_improve', 0))))}â•‘\033[0m")
    print("\033[1;36mâ• " + "â•"*58 + "â•£\033[0m")
    print("\033[1;44mâ•‘{:^58}â•‘\033[0m".format("ã€è‡ªæˆ‘å‡çº§æŠ¥å‘Šã€‘"))
    print("\033[1;36mâ• " + "â”€"*58 + "â•£\033[0m")
    print(f"\033[1;34mâ•‘ â¬†ï¸ å‡çº§æ¬¡æ•°       â”‚ \033[1;32m{state.get('upgrade_count', 0)}\033[0m{' ' * (31-len(str(state.get('upgrade_count', 0))))}â•‘\033[0m")
    print(f"\033[1;34mâ•‘ ğŸ·ï¸ å½“å‰ç‰ˆæœ¬       â”‚ \033[1;33m{state.get('version', 3.0)}\033[0m{' ' * (31-len(str(state.get('version', 3.0))))}â•‘\033[0m")
    if executed_optimizations:
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        print("\033[1;34mâ•‘      ã€æœ¬å‘¨æœŸå·²è‡ªåŠ¨æ‰§è¡Œä¼˜åŒ–ä»»åŠ¡ã€‘                 â•‘\033[0m")
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        for opt in executed_optimizations:
            print(f"â•‘ {opt:<44}â•‘")
    if deepseek_suggestion:
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        print("\033[1;34mâ•‘      ã€Deepseekå¤§æ¨¡å‹AIè‡ªåŠ¨åŒ–å»ºè®®ã€‘               â•‘\033[0m")
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        for line in deepseek_suggestion.splitlines():
            print(f"â•‘ {line[:44]:<44}â•‘")
    if gpt_suggestion:
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        print("\033[1;34mâ•‘      ã€GPTå¤§æ¨¡å‹AIåˆ›æ–°å»ºè®®ã€‘                       â•‘\033[0m")
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        for line in gpt_suggestion.splitlines():
            print(f"â•‘ {line[:44]:<44}â•‘")
    if 'ai_innovation' in state:
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        print("\033[1;34mâ•‘      ã€AIåˆ›æ–°æ–¹æ³•èåˆç»“æœã€‘                         â•‘\033[0m")
        print("\033[1;36mâ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\033[0m")
        for k, v in state['ai_innovation'].items():
            print(f"â•‘ {k.upper():<6}: {str(v)[:38]:<38}â•‘")
    print("\033[1;36mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\033[0m")
if __name__ == "__main__":
    main()
    # ä¼ ç»Ÿæ–‡åŒ–èåˆAIåˆ†ææŠ¥å‘Šå·²å–æ¶ˆï¼Œåå°è‡ªå­¦ä¹ ã€æ¨¡æ‹Ÿé¢„æµ‹ã€å¤ç›˜åˆ†æç”±ç³»ç»Ÿè‡ªåŠ¨è¿›è¡Œ